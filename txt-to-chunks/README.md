# Traitement et Recherche SÃ©mantique de Documents Markdown

Ce projet utilise **LlamaIndex** pour traiter et indexer un cours de droit administratif en Markdown, permettant une recherche sÃ©mantique intelligente.

## ğŸš€ FonctionnalitÃ©s

- **Chargement intelligent** : Parse les fichiers Markdown en prÃ©servant la hiÃ©rarchie (titres, sous-titres)
- **DÃ©coupage sÃ©mantique** : CrÃ©e des chunks logiques et cohÃ©rents
- **Indexation vectorielle** : Utilise des embeddings OpenAI pour la recherche sÃ©mantique
- **Recherche intelligente** : Trouve les passages les plus pertinents selon le sens
- **Interface interactive** : Permet de poser des questions en langage naturel

## ğŸ“‹ PrÃ©requis

1. **Python 3.8+**
2. **ClÃ© API OpenAI** (pour les embeddings et le LLM)

## ğŸ› ï¸ Installation

1. **Installer les dÃ©pendances** :
```bash
pip install -r requirements.txt
```

2. **Configurer la clÃ© API OpenAI** :
```bash
export OPENAI_API_KEY="votre_cle_api_openai"
```

## ğŸ¯ Utilisation

### ExÃ©cution du script principal

```bash
python main.py
```

### FonctionnalitÃ©s principales

1. **Chargement automatique** : Le script charge `sources/droitadminSmall.md`
2. **Indexation** : CrÃ©e un index vectoriel pour la recherche rapide
3. **Recherche sÃ©mantique** : Trouve les passages pertinents selon le sens
4. **Interface interactive** : Permet de poser des questions

### Exemples de requÃªtes

- "Qu'est-ce que l'administration?"
- "DÃ©finition des personnes publiques"
- "DiffÃ©rence entre Ã©tablissement public et collectivitÃ© territoriale"
- "Service public et externalisation"

## ğŸ—ï¸ Architecture

### Classe `MarkdownDocumentProcessor`

- **`load_and_parse_markdown()`** : Charge et parse le fichier Markdown
- **`_parse_markdown_hierarchy()`** : PrÃ©serve la structure hiÃ©rarchique
- **`create_chunks_with_hierarchy()`** : DÃ©coupe en chunks sÃ©mantiques
- **`build_index()`** : Construit l'index vectoriel
- **`search()`** : Effectue la recherche sÃ©mantique

### DÃ©coupage intelligent

- **PrÃ©servation de la hiÃ©rarchie** : Maintient les relations titre/contenu
- **Chunks sÃ©mantiques** : DÃ©coupage logique par sections
- **MÃ©tadonnÃ©es enrichies** : Titre parent, niveau, type de section

### Indexation vectorielle

- **Embeddings OpenAI** : `text-embedding-3-small`
- **Stockage persistant** : Sauvegarde dans `./storage/`
- **Recherche rapide** : SimilaritÃ© cosinus optimisÃ©e

## ğŸ“Š RÃ©sultats

Le script affiche :
- **Score de pertinence** pour chaque rÃ©sultat
- **Titre de la section** et hiÃ©rarchie
- **Extrait du contenu** pertinent
- **MÃ©tadonnÃ©es** complÃ¨tes

## ğŸ”§ Configuration

### ParamÃ¨tres modifiables

```python
processor = MarkdownDocumentProcessor(
    markdown_file_path="chemin/vers/fichier.md",
    storage_dir="./storage",
    chunk_size=1024,        # Taille des chunks
    chunk_overlap=200       # Chevauchement entre chunks
)
```

### ModÃ¨les utilisÃ©s

- **Embeddings** : `text-embedding-3-small` (OpenAI)
- **LLM** : `gpt-3.5-turbo` (OpenAI)
- **Parser** : `MarkdownNodeParser` (LlamaIndex)

## ğŸ“ Structure des fichiers

```
txt-to-chunks/
â”œâ”€â”€ main.py                 # Script principal
â”œâ”€â”€ requirements.txt        # DÃ©pendances Python
â”œâ”€â”€ README.md              # Documentation
â”œâ”€â”€ sources/
â”‚   â””â”€â”€ droitadminSmall.md # Fichier source
â””â”€â”€ storage/               # Index vectoriel (gÃ©nÃ©rÃ©)
```

## ğŸš¨ Notes importantes

1. **ClÃ© API requise** : NÃ©cessite une clÃ© API OpenAI valide
2. **PremiÃ¨re exÃ©cution** : Plus lente (construction de l'index)
3. **ExÃ©cutions suivantes** : Plus rapides (index chargÃ©)
4. **Stockage** : L'index est sauvegardÃ© dans `./storage/`

## ğŸ” Exemples de recherche

Le script inclut des exemples de recherche sÃ©mantique :

- Recherche par concepts
- Recherche par dÃ©finitions
- Recherche par comparaisons
- Recherche par processus

## ğŸ“ˆ Performance

- **Indexation** : ~30-60 secondes (premiÃ¨re fois)
- **Recherche** : ~1-3 secondes par requÃªte
- **Stockage** : ~10-50 MB selon la taille du document
