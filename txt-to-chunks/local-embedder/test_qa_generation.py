#!/usr/bin/env python3
"""
Script de test pour la g√©n√©ration de paires question/r√©ponse.
"""

import os
import sys
from pathlib import Path

# Charger les variables d'environnement depuis .env
try:
    from dotenv import load_dotenv
    load_dotenv()  # Charge le fichier .env
    print("‚úÖ Fichier .env charg√©")
except ImportError:
    print("‚ö†Ô∏è  python-dotenv non install√©, utilisation des variables d'environnement syst√®me")

# Ajouter le r√©pertoire courant au path
sys.path.append(str(Path(__file__).parent))

def test_ollama_installation():
    """Test de l'installation d'Ollama."""
    print("üîç Test de l'installation d'Ollama...")
    
    try:
        import ollama
        print("‚úÖ Ollama Python client install√©")
        return True
    except ImportError:
        print("‚ùå Ollama Python client non install√©")
        print("   Installez avec: pip install ollama")
        return False

def test_ollama_server():
    """Test de la connexion au serveur Ollama."""
    print("\nüñ•Ô∏è Test de la connexion au serveur Ollama...")
    
    try:
        import ollama
        
        # Tester la connexion
        models = ollama.list()
        print("‚úÖ Serveur Ollama accessible")
        print(f"   Mod√®les disponibles: {len(models['models'])}")
        
        # V√©rifier si Mistral est install√©
        mistral_models = [m for m in models['models'] if 'mistral' in m['name'].lower()]
        if mistral_models:
            print(f"‚úÖ Mod√®le Mistral trouv√©: {mistral_models[0]['name']}")
            return True
        else:
            print("‚ö†Ô∏è  Mod√®le Mistral non trouv√©")
            print("   Installez avec: ollama pull mistral:7b-instruct")
            return False
            
    except Exception as e:
        print(f"‚ùå Erreur de connexion √† Ollama: {e}")
        print("   Assurez-vous qu'Ollama est install√© et d√©marr√©:")
        print("   1. T√©l√©chargez depuis: https://ollama.ai")
        print("   2. Installez le mod√®le: ollama pull mistral:7b-instruct")
        return False

def test_llm_generation():
    """Test de la g√©n√©ration avec le LLM."""
    print("\nü§ñ Test de la g√©n√©ration avec le LLM...")
    
    try:
        from llama_index.llms.ollama import Ollama
        
        # Initialiser le LLM
        llm = Ollama(
            model="mistral:7b-instruct",
            temperature=0.1,
            request_timeout=30.0
        )
        
        # Test simple
        test_prompt = "Bonjour, comment allez-vous?"
        response = llm.complete(test_prompt)
        
        print("‚úÖ LLM fonctionnel")
        print(f"   R√©ponse: {str(response)[:100]}...")
        return True
        
    except Exception as e:
        print(f"‚ùå Erreur avec le LLM: {e}")
        return False

def test_qa_generation():
    """Test de la g√©n√©ration de paires Q/R."""
    print("\n‚ùì Test de la g√©n√©ration de paires Q/R...")
    
    try:
        from main import MarkdownDocumentProcessorLocal
        
        processor = MarkdownDocumentProcessorLocal(
            markdown_file_path="../sources/droitadminSmall.md",
            storage_dir="./test_storage_qa",
            llm_model="mistral:7b-instruct"
        )
        
        # Charger un petit √©chantillon
        documents = processor.load_and_parse_markdown()
        if not documents:
            print("‚ùå Aucun document trouv√©")
            return False
        
        # Prendre seulement le premier document pour le test
        test_doc = documents[0]
        print(f"‚úÖ Document de test: {test_doc.metadata.get('title', 'Sans titre')}")
        
        # Test de g√©n√©ration de questions
        questions = processor._generate_questions_for_chunk(test_doc)
        if questions:
            print(f"‚úÖ Questions g√©n√©r√©es: {len(questions)}")
            for i, q in enumerate(questions, 1):
                print(f"   {i}. {q}")
        else:
            print("‚ùå Aucune question g√©n√©r√©e")
            return False
        
        # Test de g√©n√©ration de r√©ponse
        if questions:
            answer = processor._generate_answer_for_question(questions[0], test_doc)
            if answer:
                print(f"‚úÖ R√©ponse g√©n√©r√©e: {answer[:100]}...")
                return True
            else:
                print("‚ùå Aucune r√©ponse g√©n√©r√©e")
                return False
        
        return True
        
    except Exception as e:
        print(f"‚ùå Erreur lors du test Q/R: {e}")
        return False

def test_jsonl_format():
    """Test du format JSONL."""
    print("\nüìÑ Test du format JSONL...")
    
    try:
        import json
        
        # Cr√©er un exemple de paire Q/R
        qa_pair = {
            "messages": [
                {"role": "user", "content": "Qu'est-ce que l'administration?"},
                {"role": "assistant", "content": "L'administration est l'ensemble des personnes publiques fran√ßaises."}
            ]
        }
        
        # Tester la s√©rialisation JSON
        json_str = json.dumps(qa_pair, ensure_ascii=False)
        parsed = json.loads(json_str)
        
        print("‚úÖ Format JSONL valide")
        print(f"   Exemple: {json_str[:100]}...")
        return True
        
    except Exception as e:
        print(f"‚ùå Erreur avec le format JSONL: {e}")
        return False

def main():
    """Fonction principale de test."""
    print("üß™ TESTS DE G√âN√âRATION Q/R")
    print("=" * 60)
    
    tests = [
        ("Installation Ollama", test_ollama_installation),
        ("Serveur Ollama", test_ollama_server),
        ("G√©n√©ration LLM", test_llm_generation),
        ("G√©n√©ration Q/R", test_qa_generation),
        ("Format JSONL", test_jsonl_format)
    ]
    
    results = []
    
    for test_name, test_func in tests:
        try:
            result = test_func()
            results.append((test_name, result))
        except Exception as e:
            print(f"‚ùå Erreur dans {test_name}: {e}")
            results.append((test_name, False))
    
    # R√©sum√© des tests
    print("\n" + "=" * 60)
    print("üìä R√âSUM√â DES TESTS")
    print("=" * 60)
    
    passed = 0
    total = len(results)
    
    for test_name, result in results:
        status = "‚úÖ PASS" if result else "‚ùå FAIL"
        print(f"{status} {test_name}")
        if result:
            passed += 1
    
    print(f"\nüéØ R√©sultat: {passed}/{total} tests r√©ussis")
    
    if passed == total:
        print("üéâ Tous les tests sont pass√©s! La g√©n√©ration Q/R est pr√™te.")
        print("\nüí° Pour g√©n√©rer des donn√©es d'entra√Ænement:")
        print("   python main.py")
        print("   Choisissez l'option 2")
    else:
        print("‚ö†Ô∏è  Certains tests ont √©chou√©. V√©rifiez les erreurs ci-dessus.")
        print("\nüîß Solutions possibles:")
        print("   1. Installez Ollama: https://ollama.ai")
        print("   2. Installez le mod√®le: ollama pull mistral:7b-instruct")
        print("   3. V√©rifiez que le serveur Ollama fonctionne")
    
    return passed == total

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
